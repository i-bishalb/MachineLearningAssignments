# MachineLearning Assignments <br>

[Machine Learning Assignments (Small projects)](https://github.com/i-bishalb/MachineLearningAssignments)
    These are some of the projects that were carried out while taking courses with machine learning. <br>
    1. **Regression**
       1. [Predicting Housing Prices](https://github.com/i-bishalb/MachineLearningAssignments/blob/main/Predicting_Housing_Prices_Regression/Predicting_Housing_Prices_Regression.ipynb): <br>
     In this project, I have predicted housing prices using the boston housing data. I have used **Linear Regression** and regularized regression methods: **Lasso Regression**, **Ridge Regression** and **ElasticNet Regression** to predict the housing prices. Polynomial of degree 2 does a good job in predicting housing prices. Best models for each method were selected using extensive gridsearch. All 3 regularized models (**Lasso Regression**, **Ridge Regression** and **ElasticNet Regression**) show similar accuracy for prediction. <br>
       2. [California Housing Prices](https://github.com/i-bishalb/MachineLearningAssignments/blob/main/Housing_Prices_Regression/California_Housing_Regression.ipynb): <br> 
      In this project, I have carried out regression calculations to predict housing prices using the california housing data. I have used Linear models:
      **Linear Regression**, **Ridge Regression** and Non-linear models **Random Forest Regression**, **K-Nearest Neighbor Regression** and **Support Vector Machine Regression (with gaussian kernel (rbf))**. The model highlights the complexity in some dataset and the need to use non-linear or beyond linear models to get an accurate prediction.<br>
     2. **Classification**
        1. [Churn prediction](https://github.com/i-bishalb/MachineLearningAssignments/blob/main/Bank_Customers_Churn_Classification/Churn_Classification.ipynb): <br>
           In this project, I have carried out binary classification prediction to predict customers churning or not-churing. I have used 7 classifiers for the problem namely: **Logistic Regression**, **Random Forest Classifier**, **Decision Tree Classifier**, **K Neighbors Classifier**, **Support Vector Machine Classifier** and Boosting methods **Ada Boost Classifier** and **Gradient Boosting Classifier**. The two boosting methods and Random Forest Classifier have the best predictions. A majority **Voting classifier** shows same accuracy as the best three classifiers. 
        
   
